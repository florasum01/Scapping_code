import scrapy 
import json 
import csv
from datetime import datetime
class ChaldalSpider(scrapy.Spider): 
    name = 'chaldal_final_SKU_lalbagh' 
    # custom_settings = {
    #     'FEED_URI': 'Chaldal_' + datetime.datetime.today().strftime('%y%m%d') + '.csv',
    #     'FEED_FORMAT': 'csv',
    #     'FEED_EXPORTERS': {
    #         'csv': 'scrapy.exporters.CsvItemExporter',
    #     },
    #     'FEED_EXPORT_ENCODING': 'utf-8',
    # }
    custom_settings = {"FEEDS":{"chaldal_lalbagh.csv":{"format":"csv"}}}
    def start_requests(self): 
        headers = { 
        'authority': 'catalog.chaldal.com', 
        'pragma': 'no-cache', 
        'cache-control': 'no-cache', 
        'accept': 'application/json', 
        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36', 
        'content-type': 'application/json, application/json',
        'sec-gpc': '1', 
        'origin': 'https://chaldal.com',
        'sec-fetch-site': 'same-site',
        'sec-fetch-mode': 'cors', 
        'sec-fetch-dest': 'empty', 
        'referer': 'https://chaldal.com/', 
        'accept-language': 'en-US,en;q=0.9' 
        } 
 
        form_data = {
        "apiKey": "e964fc2d51064efa97e94db7c64bf3d044279d4ed0ad4bdd9dce89fecc9156f0",
        "storeId": 1, 
        "warehouseId": 45, 
        "pageSize": 10000,
        # changed from default 50 to 300 to get all values in one request 
        "currentPageIndex": 0, 
        "metropolitanAreaId": 1, 
        "query": "", 
        "productVariantId": -1,
        "canSeeOutOfStock": "false", 
        "filters": [] 
        } 

        yield scrapy.Request(url='https://catalog.chaldal.com/searchOld', 
        method='POST', 
        body=json.dumps(form_data),
        headers=headers ) 
    def parse(self, response): 
            data = response.json() 
            for product in data.get('hits'): 
                yield { 'Product Name' : product['name'], 'Product Price' : product['mrp'], 'Discounted Price' : product['corpPrice'] , 'Discount flag' : product['doNotApplyDiscounts'],
                'product_slug' : product['slug'],'product_qty_weight' : product['subText'],'Broad_Cat' : product['categories'],'Segregated_cat' : product['recursiveCategories'],'Product_name_as_shown_website' : product['nameWithoutSubText']
                ,'productAvailabilityForSelectedWarehouse' : product['productAvailabilityForSelectedWarehouse'] 
                
                }

    #             from scrapy.crawler import CrawlerProcess
    #             c = CrawlerProcess({
    #             'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36',
    #             'FEED_FORMAT': 'csv',
    #             'FEED_URI': 'output.csv',
    # # 'DEPTH_LIMIT': 2,
    # # 'CLOSESPIDER_PAGECOUNT': 3,
    #     })
    #         c.crawl(ChaldalSpider, urls_file='input.txt')
    #         c.start()
